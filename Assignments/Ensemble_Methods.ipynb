{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3c13e1",
   "metadata": {},
   "source": [
    "### 1. Do get the data file and take 100 data from the notepad file to csv. Next by taking different technique do calculate the efficiency of the model. Data should represent minimum 100 records and all classes should be present in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c8fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d2f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 records (%):  97.0\n",
      "For 70 records (%):  91.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Nirmalya Majhi\\Desktop\\Advanced IT Workshop\\cancer.csv')\n",
    "df.drop(['Sample Code Number', 'id'],axis = 1, inplace= True)\n",
    "impute_value = df.values\n",
    "imputer = SimpleImputer()\n",
    "imputeData = imputer.fit_transform(impute_value)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normalizedData = scaler.fit_transform(impute_value)\n",
    "X = normalizedData[:,0:9]\n",
    "Y = normalizedData[:,9]\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv = kfold)\n",
    "print(\"For 100 records (%): \",round(results.mean(),2)*100)\n",
    "seed = 7\n",
    "num_trees = 70\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv = kfold)\n",
    "print(\"For 70 records (%): \",round(results.mean(),2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e85da5",
   "metadata": {},
   "source": [
    "Discussion: Ensemble models combine the decisions from multiple models to improve the overall performance. We can see increasing the number of records, the accuracy of our model increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff9695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
